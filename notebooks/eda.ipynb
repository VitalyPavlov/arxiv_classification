{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b6754e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from bertopic import BERTopic\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from typing import List, Iterable\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import json\n",
    "from jsonformer import Jsonformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "293b56df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vitaly/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/vitaly/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/vitaly/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98755f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/arxiv-metadata-oai-snapshot.json', lines=True, chunksize=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17003abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>Pavel Nadolsky</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>37 pages, 15 figures; published version</td>\n",
       "      <td>Phys.Rev.D76:013009,2007</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>ANL-HEP-PR-07-12</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>None</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0002</td>\n",
       "      <td>Louis Theran</td>\n",
       "      <td>Ileana Streinu and Louis Theran</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>To appear in Graphs and Combinatorics</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2008-12-13</td>\n",
       "      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       submitter  \\\n",
       "0  704.0001  Pavel Nadolsky   \n",
       "1  704.0002    Louis Theran   \n",
       "\n",
       "                                             authors  \\\n",
       "0  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1                    Ileana Streinu and Louis Theran   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1           Sparsity-certifying Graph Decompositions   \n",
       "\n",
       "                                  comments               journal-ref  \\\n",
       "0  37 pages, 15 figures; published version  Phys.Rev.D76:013009,2007   \n",
       "1    To appear in Graphs and Combinatorics                      None   \n",
       "\n",
       "                          doi         report-no     categories  \\\n",
       "0  10.1103/PhysRevD.76.013009  ANL-HEP-PR-07-12         hep-ph   \n",
       "1                        None              None  math.CO cs.CG   \n",
       "\n",
       "                                             license  \\\n",
       "0                                               None   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    A fully differential calculation in perturba...   \n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2008-11-26   \n",
       "1  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2008-12-13   \n",
       "\n",
       "                                      authors_parsed  \n",
       "0  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
       "1           [[Streinu, Ileana, ], [Theran, Louis, ]]  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk = next(df)\n",
    "chunk.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de831c",
   "metadata": {},
   "source": [
    "# Unique categories of abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "652ec4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'astro-ph': 208,\n",
       "         'hep-th': 89,\n",
       "         'hep-ph': 80,\n",
       "         'quant-ph': 67,\n",
       "         'cond-mat.mtrl-sci': 56,\n",
       "         'gr-qc': 55,\n",
       "         'cond-mat.str-el': 55,\n",
       "         'cond-mat.mes-hall': 50,\n",
       "         'cond-mat.stat-mech': 47,\n",
       "         'math-ph': 35,\n",
       "         'math.MP': 35,\n",
       "         'nucl-th': 32,\n",
       "         'cond-mat.other': 29,\n",
       "         'cond-mat.supr-con': 29,\n",
       "         'math.CO': 25,\n",
       "         'math.AG': 25,\n",
       "         'math.PR': 25,\n",
       "         'hep-ex': 24,\n",
       "         'physics.optics': 24,\n",
       "         'cond-mat.soft': 23,\n",
       "         'math.AP': 21,\n",
       "         'nucl-ex': 20,\n",
       "         'cond-mat.dis-nn': 19,\n",
       "         'physics.gen-ph': 18,\n",
       "         'math.DG': 18,\n",
       "         'cs.IT': 17,\n",
       "         'math.IT': 17,\n",
       "         'math.CA': 15,\n",
       "         'math.RT': 14,\n",
       "         'math.CV': 13,\n",
       "         'math.NT': 12,\n",
       "         'math.QA': 12,\n",
       "         'physics.soc-ph': 12,\n",
       "         'physics.data-an': 12,\n",
       "         'physics.comp-ph': 11,\n",
       "         'math.ST': 11,\n",
       "         'stat.TH': 11,\n",
       "         'physics.chem-ph': 10,\n",
       "         'math.FA': 9,\n",
       "         'math.GT': 9,\n",
       "         'physics.atom-ph': 9,\n",
       "         'math.GR': 8,\n",
       "         'nlin.PS': 7,\n",
       "         'math.RA': 7,\n",
       "         'q-bio.PE': 7,\n",
       "         'hep-lat': 7,\n",
       "         'math.OA': 7,\n",
       "         'math.DS': 7,\n",
       "         'cs.CC': 7,\n",
       "         'math.OC': 7,\n",
       "         'nlin.CD': 6,\n",
       "         'cs.PF': 6,\n",
       "         'math.AT': 5,\n",
       "         'math.NA': 5,\n",
       "         'physics.flu-dyn': 5,\n",
       "         'math.AC': 5,\n",
       "         'physics.plasm-ph': 4,\n",
       "         'cs.AI': 4,\n",
       "         'cs.DS': 4,\n",
       "         'math.SG': 4,\n",
       "         'math.KT': 4,\n",
       "         'physics.class-ph': 4,\n",
       "         'nlin.SI': 3,\n",
       "         'cs.NE': 3,\n",
       "         'q-bio.OT': 3,\n",
       "         'q-bio.BM': 3,\n",
       "         'math.SP': 3,\n",
       "         'q-bio.NC': 3,\n",
       "         'cs.CR': 3,\n",
       "         'q-fin.ST': 3,\n",
       "         'math.GM': 3,\n",
       "         'q-bio.MN': 2,\n",
       "         'q-bio.CB': 2,\n",
       "         'q-bio.QM': 2,\n",
       "         'physics.space-ph': 2,\n",
       "         'physics.ed-ph': 2,\n",
       "         'physics.bio-ph': 2,\n",
       "         'cs.DM': 2,\n",
       "         'math.MG': 2,\n",
       "         'physics.ins-det': 2,\n",
       "         'q-fin.CP': 2,\n",
       "         'q-fin.PR': 2,\n",
       "         'cs.NI': 2,\n",
       "         'cs.LG': 2,\n",
       "         'stat.ME': 2,\n",
       "         'physics.hist-ph': 2,\n",
       "         'cs.CG': 1,\n",
       "         'physics.pop-ph': 1,\n",
       "         'cs.CE': 1,\n",
       "         'cs.MS': 1,\n",
       "         'cs.NA': 1,\n",
       "         'nlin.CG': 1,\n",
       "         'cs.LO': 1,\n",
       "         'physics.ao-ph': 1,\n",
       "         'physics.geo-ph': 1,\n",
       "         'q-fin.RM': 1,\n",
       "         'q-bio.SC': 1,\n",
       "         'astro-ph.HE': 1,\n",
       "         'math.CT': 1,\n",
       "         'math.LO': 1,\n",
       "         'q-fin.GN': 1,\n",
       "         'stat.AP': 1,\n",
       "         'physics.atm-clus': 1,\n",
       "         'cs.SE': 1,\n",
       "         'physics.acc-ph': 1,\n",
       "         'math.GN': 1,\n",
       "         'stat.CO': 1,\n",
       "         'cs.AR': 1})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_categories = [xx for x in chunk.categories.values for xx in x.split(' ')]\n",
    "Counter(unique_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86bd55",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL_REGEX = re.compile(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\")\n",
    "HTML_TAG_REGEX = re.compile(r\"<.*?>\")\n",
    "PUNCT_TABLE = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove stopwords from a text.\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = text.split()\n",
    "    filtered = [t for t in tokens if t.lower() not in stop_words]\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "def remove_emails_and_html(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove email addresses and HTML tags from a text.\n",
    "    \"\"\"\n",
    "    no_emails = EMAIL_REGEX.sub(\" \", text)\n",
    "    no_html = HTML_TAG_REGEX.sub(\" \", no_emails)\n",
    "    no_html = re.sub(r\"\\s+\", \" \", no_html).strip()\n",
    "    return no_html\n",
    "\n",
    "def remove_punctuation(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove all punctuation characters from a text.\n",
    "    \"\"\"\n",
    "    return text.translate(PUNCT_TABLE)\n",
    "\n",
    "def filter_short_docs(docs: List[str], min_tokens: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Keep only documents that have at least `min_tokens` tokens.\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    for doc in docs:\n",
    "        n_tokens = len(doc.split())\n",
    "        if n_tokens >= min_tokens:\n",
    "            filtered.append(doc)\n",
    "    return filtered\n",
    "\n",
    "def lemmatize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Lemmatize text using spaCy.\n",
    "    \n",
    "    python -m spacy download en_core_web_sm\n",
    "\n",
    "    Returns a space-joined string of lemmas.\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_space]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = remove_emails_and_html(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = text.lower()\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a226e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk['abstract_post'] = chunk['abstract'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962f2e8",
   "metadata": {},
   "source": [
    "# BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b6445ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:04<00:00,  6.56it/s]\n",
      "2025-12-02 18:14:06,227 - BERTopic - Predicting topic assignments through cosine similarity of topic and document embeddings.\n",
      "/Users/vitaly/Documents/Github/iris/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vitaly/Documents/Github/iris/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/vitaly/Documents/Github/iris/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic.load(\"MaartenGr/BERTopic_Wikipedia\")\n",
    "topic, prob = topic_model.transform(chunk.abstract_post.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c746eb9a",
   "metadata": {},
   "source": [
    "# Example of BERTopic output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e00932fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract\n",
      "  In this paper we present an algorithm for computing Hecke eigensystems of\n",
      "Hilbert-Siegel cusp forms over real quadratic fields of narrow class number\n",
      "one. We give some illustrative examples using the quadratic field\n",
      "$\\Q(\\sqrt{5})$. In those examples, we identify Hilbert-Siegel eigenforms that\n",
      "are possible lifts from Hilbert eigenforms.\n",
      "\n",
      "Cluster label\n",
      "18_matrices_matrix_transpose_eigenvector\n",
      "\n",
      "Top words\n",
      "[['matrices', 0.6521367430686951], ['matrix', 0.6065698862075806], ['transpose', 0.39497610926628113], ['eigenvector', 0.37739312648773193], ['multiplication', 0.3743625283241272], ['eigenvectors', 0.35193151235580444], ['columns', 0.3202955722808838], ['tensors', 0.3159672021865845], ['quaternions', 0.3140992224216461], ['determinants', 0.31085848808288574]]\n"
     ]
    }
   ],
   "source": [
    "text_id = 10\n",
    "topic_id = topic[text_id]\n",
    "text = chunk.abstract.values[text_id]\n",
    "\n",
    "print('Abstract')\n",
    "print(text)\n",
    "\n",
    "print('Cluster label')\n",
    "print(topic_model.topic_labels_[topic_id])\n",
    "print()\n",
    "\n",
    "print('Top words')\n",
    "print(topic_model.get_topic(topic_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa107240",
   "metadata": {},
   "source": [
    "# LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d643b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.80s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"hight_level_topic\": {\"type\": \"string\"},\n",
    "        \"low_level_topic\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"hight_level_topic\", \"low_level_topic\"],\n",
    "}\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-3B\"                \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",             \n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b6fc6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(top_words, text):\n",
    "    prompt = f\"\"\"\n",
    "        These are the keywords of a group of scientific articles: {top_words}.\n",
    "\n",
    "        This is an example of the abstract of one article in this group:\n",
    "        {text}\n",
    "\n",
    "        What are the high- and low-level topics of this group of articles?\n",
    "\n",
    "        You must fill:\n",
    "        - hight_level_topic (string)\n",
    "        - low_level_topic (string)\n",
    "\n",
    "        hight_level_topic is a general scientific discipline like Mathematics, Physics, Medicide and so on.\n",
    "        low_level_topic is a specific subtopic of the defined scientific discipline.\n",
    "\n",
    "        Return ONLY the structured data.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76362a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response: {\n",
      "  \"hight_level_topic\": \"Mathematics\",\n",
      "  \"low_level_topic\": \"Number theory\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text_id = 10\n",
    "topic_id = topic[text_id]\n",
    "text = chunk.abstract.values[text_id]\n",
    "top_words = topic_model.get_topic(topic_id)\n",
    "\n",
    "prompt = get_prompt(top_words, text)\n",
    "\n",
    "generator = Jsonformer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    json_schema=schema,\n",
    "    prompt=prompt,\n",
    "    max_array_length=10,\n",
    "    max_number_tokens=5,\n",
    ")\n",
    "\n",
    "raw_result = generator()\n",
    "print(\"LLM response:\", json.dumps(raw_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7cccaf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2377/2377 [00:00<00:00, 23056.13it/s]\n"
     ]
    }
   ],
   "source": [
    "topic_words = topic_model.get_topics()\n",
    "representative_texts = dict() \n",
    "\n",
    "for topic_id, _ in tqdm(topic_words.items()):\n",
    "    if sum(topic==topic_id) > 0:\n",
    "        representative_texts[topic_id] = random.choice(chunk.abstract.values[topic==topic_id])\n",
    "    else:\n",
    "        representative_texts[topic_id] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4cdc107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 194/2377 [33:33<6:17:39, 10.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 16\u001b[0m\n\u001b[1;32m      5\u001b[0m prompt \u001b[38;5;241m=\u001b[39m get_prompt(top_words, text)\n\u001b[1;32m      7\u001b[0m generator \u001b[38;5;241m=\u001b[39m Jsonformer(\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      9\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     max_number_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m raw_result \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m prediction[topic_id] \u001b[38;5;241m=\u001b[39m raw_result\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/jsonformer/main.py:242\u001b[0m, in \u001b[0;36mJsonformer.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 242\u001b[0m     generated_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_schema\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproperties\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generated_data\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/jsonformer/main.py:147\u001b[0m, in \u001b[0;36mJsonformer.generate_object\u001b[0;34m(self, properties, obj)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, schema \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[generate_object] generating value for\u001b[39m\u001b[38;5;124m\"\u001b[39m, key)\n\u001b[0;32m--> 147\u001b[0m     obj[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/jsonformer/main.py:174\u001b[0m, in \u001b[0;36mJsonformer.generate_value\u001b[0;34m(self, schema, obj, key)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m         obj\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_marker)\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m schema_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    176\u001b[0m     new_array \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/jsonformer/main.py:112\u001b[0m, in \u001b[0;36mJsonformer.generate_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[generate_string]\u001b[39m\u001b[38;5;124m\"\u001b[39m, prompt, is_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    108\u001b[0m input_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    110\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_string_token_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mStringStoppingCriteria\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Some models output the prompt as part of the response\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# This removes the prompt from the response if it is present\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mlen\u001b[39m(response[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_tokens[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (response[\u001b[38;5;241m0\u001b[39m][: \u001b[38;5;28mlen\u001b[39m(input_tokens[\u001b[38;5;241m0\u001b[39m])] \u001b[38;5;241m==\u001b[39m input_tokens)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    128\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1479\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1463\u001b[0m         input_ids,\n\u001b[1;32m   1464\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1476\u001b[0m     )\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1478\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/transformers/generation/utils.py:2340\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2337\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2339\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2340\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2348\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/accelerate/hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:1173\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1170\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1186\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:1058\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1049\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1050\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         use_cache,\n\u001b[1;32m   1056\u001b[0m     )\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1058\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/accelerate/hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:770\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m    past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    768\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 770\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    773\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    774\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    775\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    780\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 170\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/accelerate/hooks.py:341\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m named_module_tensors(\n\u001b[1;32m    335\u001b[0m     module,\n\u001b[1;32m    336\u001b[0m     include_buffers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffload_buffers,\n\u001b[1;32m    337\u001b[0m     recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_submodules,\n\u001b[1;32m    338\u001b[0m     remove_non_persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    339\u001b[0m ):\n\u001b[1;32m    340\u001b[0m     fp16_statistics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_map\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint8:\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/accelerate/utils/offload.py:118\u001b[0m, in \u001b[0;36mPrefixedDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Github/iris/venv/lib/python3.9/site-packages/accelerate/utils/offload.py:171\u001b[0m, in \u001b[0;36mOffloadedWeightsLoader.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(weight_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafetensors_file\u001b[39m\u001b[38;5;124m\"\u001b[39m], framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 171\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# if failed to get_tensor on the device, such as bf16 on mps, try to load it on CPU first\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(weight_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafetensors_file\u001b[39m\u001b[38;5;124m\"\u001b[39m], framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prediction = dict()\n",
    "for topic_id, text in tqdm(representative_texts.items()):\n",
    "    top_words = [x for x in topic_words[topic_id]]\n",
    "\n",
    "    prompt = get_prompt(top_words, text)\n",
    "\n",
    "    generator = Jsonformer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        json_schema=schema,\n",
    "        prompt=prompt,\n",
    "        max_array_length=10,\n",
    "        max_number_tokens=5,\n",
    "    )\n",
    "\n",
    "    raw_result = generator()\n",
    "\n",
    "    prediction[topic_id] = raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1892a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/title_prediction.json', 'w') as f:\n",
    "    json.dump(prediction, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d37744ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract\n",
      "  In this paper we present an algorithm for computing Hecke eigensystems of\n",
      "Hilbert-Siegel cusp forms over real quadratic fields of narrow class number\n",
      "one. We give some illustrative examples using the quadratic field\n",
      "$\\Q(\\sqrt{5})$. In those examples, we identify Hilbert-Siegel eigenforms that\n",
      "are possible lifts from Hilbert eigenforms.\n",
      "\n",
      "Cluster label\n",
      "834_integers_primes_integer_prime\n",
      "\n",
      "Top words\n",
      "[['integers', 0.5680645704269409], ['primes', 0.5572009086608887], ['integer', 0.484574556350708], ['prime', 0.47240108251571655], ['arithmetic', 0.4225975275039673], ['multiplicative', 0.42088091373443604], ['divisors', 0.39332306385040283], ['divides', 0.3841027021408081], ['numbers', 0.360837459564209], ['divisibility', 0.3401588201522827]]\n",
      "\n",
      "Title prediction\n",
      "{'hight_level_topic': 'Mathematics', 'low_level_topic': 'Number theory'}\n"
     ]
    }
   ],
   "source": [
    "text_id = 10\n",
    "topic_id = topic[text_id]\n",
    "text = chunk.abstract.values[text_id]\n",
    "title = prediction[topic_id]\n",
    "\n",
    "print('Abstract')\n",
    "print(text)\n",
    "\n",
    "print('Cluster label')\n",
    "print(topic_model.topic_labels_[topic_id])\n",
    "print()\n",
    "\n",
    "print('Top words')\n",
    "print(topic_model.get_topic(topic_id))\n",
    "print()\n",
    "\n",
    "print('Title prediction')\n",
    "print(prediction[topic_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e906d",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ce74c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concentration_score(counts: dict[str, int]) -> float:\n",
    "    values = list(counts.values())\n",
    "    K = len(values)\n",
    "\n",
    "    if K == 1:\n",
    "        return 1.0\n",
    "\n",
    "    total = sum(values)\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "\n",
    "    ps = [v / total for v in values if v > 0]\n",
    "\n",
    "    H = -sum(p * math.log(p) for p in ps)\n",
    "    H_norm = H / math.log(K)\n",
    "\n",
    "    return 1.0 - H_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1914994a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [ph]\n",
       "1      [cs, math]\n",
       "2       [physics]\n",
       "3          [math]\n",
       "4          [math]\n",
       "          ...    \n",
       "995          [th]\n",
       "996        [math]\n",
       "997        [math]\n",
       "998        [math]\n",
       "999          [ex]\n",
       "Name: high_level_categories, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk['high_level_categories'] = chunk.categories.apply(lambda x: set([xx.split('.')[0] for xx in x.split(' ')]))\n",
    "chunk['high_level_categories'] = chunk['high_level_categories'].apply(lambda x: [xx.split('-', 1)[1] if '-' in xx else xx for xx in x])\n",
    "chunk['high_level_categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2161c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:00<00:00, 4823.72it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "for label in tqdm(np.unique(topic)):\n",
    "    mask = topic == label\n",
    "    categories_count = Counter([xx for x in chunk.loc[mask, 'high_level_categories'].values for xx in x])\n",
    "    metrics.append(concentration_score(categories_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "13758e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(metrics)\n",
    "plt.xlabel('Metrics values per class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "477c5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sport_article = [\"\"\"\n",
    "# A popular quantitative approach to evaluating player performance in sports involves comparing an observed outcome to the expected outcome ignoring player involvement, which is estimated using statistical or machine learning methods. In soccer, for instance, goals above expectation (GAX) of a player measure how often shots of this player led to a goal compared to the model-derived expected outcome of the shots. Typically, sports data analysts rely on flexible machine learning models, which are capable of handling complex nonlinear effects and feature interactions, but fail to provide valid statistical inference due to finite-sample bias and slow convergence rates. In this paper, we close this gap by presenting a framework for player evaluation with metrics derived from differences in actual and expected outcomes using flexible machine learning algorithms, which nonetheless allows for valid frequentist inference. We first show that the commonly used metrics are directly related to Rao's score test in parametric regression models for the expected outcome. Motivated by this finding and recent developments in double machine learning, we then propose the use of residualized versions of the original metrics. For GAX, the residualization step corresponds to an additional regression predicting whether a given player would take the shot under the circumstances described by the features. We further relate metrics in the proposed framework to player-specific effect estimates in interpretable semiparametric regression models, allowing us to infer directional effects, e.g., to determine players that have a positive impact on the outcome. Our primary use case are GAX in soccer. We further apply our framework to evaluate goal-stopping ability of goalkeepers, shooting skill in basketball, quarterback passing skill in American football, and injury-proneness of soccer players.\n",
    "# \"\"\"]\n",
    "\n",
    "# sport_topic, sport_prob = topic_model.transform(sport_article)\n",
    "# topic_id = sport_topic[0]\n",
    "\n",
    "# print('Abstract')\n",
    "# print(sport_article)\n",
    "\n",
    "# print('Cluster label')\n",
    "# print(topic_model.topic_labels_[topic_id])\n",
    "# print()\n",
    "\n",
    "# print('Top words')\n",
    "# print(topic_model.get_topic(topic_id))\n",
    "# print()\n",
    "\n",
    "# print('Title prediction')\n",
    "# print(prediction[topic_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227285f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
